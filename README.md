# ğŸ§  ChatBot Project (Weaviate + LLM)

An intelligent, retrieval-augmented chatbot system that lets you ask **FAQ or product-related questions** and get **context-aware answers** powered by **Weaviate (vector database)** and a **large language model (LLM)** such as Together AI or OpenAI.

Weaviate handles all **embedding and semantic search** inside Docker, while your Jupyter notebook orchestrates the **retrieval + generation** flow.

---

## âš™ï¸ How It Works â€” Chatbot Workflow

Imagine youâ€™ve uploaded your companyâ€™s documentation or FAQs into the system.
Now you ask:

> â€œHow can I reset my productâ€™s access key?â€

Hereâ€™s what happens step by step ğŸ‘‡

### ğŸ§© 1. The Question (User Input)

You type your question into the notebook (or future UI/chat interface).

* The question is treated as a **query vector** by Weaviate.
* No local embedding code is needed â€” Weaviateâ€™s internal `text2vec` module handles embedding creation.

### ğŸ” 2. Retrieval from Weaviate

Weaviate receives the vectorized question and performs a **similarity search** in its database:

* It compares your questionâ€™s vector with the stored vectors of your product documents, FAQs, or manuals.
* The top-K most semantically relevant text chunks are returned (these are the â€œcontext snippetsâ€).

This ensures the chatbot doesnâ€™t â€œhallucinateâ€ â€” it grounds its answers in real company data.

### ğŸ§  3. Context Assembly

The notebook collects those top-K snippets and builds a **context-rich prompt** for the LLM:

```
User Question:
"How can I reset my productâ€™s access key?"

Relevant Context:
1. "Access keys can be reset from the account settings page..."
2. "To generate a new key, navigate to..."

Instruction:
"Using the information above, answer clearly and concisely."
```

### ğŸ’¬ 4. Generation (LLM)

That structured prompt is sent to the LLM (Together AI or OpenAI).

The model:

* Reads the context retrieved from Weaviate.
* Generates a natural language answer grounded in those snippets.
* The result might be:

  > â€œYou can reset your access key from the Account Settings â†’ Security tab, then select â€˜Generate New Keyâ€™.â€


* **Weaviate (Vector DB)** â€“ runs inside Docker; handles all embeddings and semantic search.
* **LLM API (Together / OpenAI)** â€“ provides reasoning and natural-language generation.
* **Notebook** â€“ coordinates the flow: ask â†’ retrieve â†’ generate â†’ display.

---

## ğŸ§ª Typical Use Cases

* **FAQ Chatbot** â€“ upload company FAQs, ask questions in natural language.
* **Product Support Assistant** â€“ give product manuals or help docs as knowledge base.
* **Documentation Query Bot** â€“ search through technical docs or reports conversationally.
* **Knowledge RAG Demo** â€“ educational project showing real retrieval-augmented generation flow.

---

## ğŸš€ Quickstart

1. **Start Weaviate**

   ```bash
   docker compose up -d
   ```

   This starts the vector database with its embedding module.

2. **(Optional) Add LLM API Key**

   ```bash
   export TOGETHER_API_KEY=...
   # or
   export OPENAI_API_KEY=...
   ```

3. **Open Notebook**

   ```bash
   jupyter notebook ChatBot_Proj.ipynb
   ```

4. **Run through the cells**:

   * Create schema
   * Ingest your FAQ or product data
   * Ask questions and see retrieval + LLM responses

---


## ğŸ§° Tech Stack

* **Weaviate** â€“ Vector database for storage, embeddings, and semantic search
* **Together AI / OpenAI** â€“ Text generation (LLM)
* **Python + Jupyter** â€“ Orchestration and experimentation
* **Docker Compose** â€“ Environment setup for Weaviate and its modules


